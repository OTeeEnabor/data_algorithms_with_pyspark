# Introduction to Spark and Pyspark

Key points from this chapter

1. Spark is fast and powerful analytics engine because it uses in-memory operation, and its use of robust, distributed, fault-tolerant data abstractions - resilient distributed datasets (RDDs) and DataFrames.
2. Transformations of data in with Spark can be performed in 4 different programming languages - Java, Scala, R, and Python. This book covers Python's API for Spark - PySpark - which is popular for solving big data problems by efficiently transforming data into the desired result and format.
3. Big data can be represented using the aforementioned distributed data abstractions provided by Spark.